{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.36.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.19.4)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: requests in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\dmitriy drozhzhin\\appdata\\roaming\\python\\python310\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.10.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\dmitriy drozhzhin\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2023.7.22)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.0.7)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Dmitriy Drozhzhin\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement transformers.utils (from versions: none)\n",
      "ERROR: No matching distribution found for transformers.utils\n",
      "WARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Dmitriy Drozhzhin\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\dmitriy drozhzhin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.26.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 23.3.1 is available.\n",
      "You should consider upgrading via the 'c:\\Users\\Dmitriy Drozhzhin\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%pip install -U transformers\n",
    "%pip install -Uq transformers.utils\n",
    "%pip install -U numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import random\n",
    "import spacy\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "nlp = spacy.load('ru_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.stem.snowball import SnowballStemmer\n",
    "# nltk.download('stopwords')\n",
    "# from nltk.corpus import stopwords\n",
    "# stop_words = set(stopwords.words('russian'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>В Альфа-Банке работает замечательная девушка -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Оформляя рассрочку в м. Видео в меге тёплый ст...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>Очень порадовала оперативность работы в банке....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Имела неосторожность оформить потреб. кредит в...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Небольшая предыстория: Нашел на сайте MDM банк...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idx     Score                                               Text\n",
       "0    0  Positive  В Альфа-Банке работает замечательная девушка -...\n",
       "1    1  Negative  Оформляя рассрочку в м. Видео в меге тёплый ст...\n",
       "2    2  Positive  Очень порадовала оперативность работы в банке....\n",
       "3    3  Negative  Имела неосторожность оформить потреб. кредит в...\n",
       "4    4  Negative  Небольшая предыстория: Нашел на сайте MDM банк..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"banks.csv\", sep=\"\\t\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13999 entries, 0 to 13998\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   idx     13999 non-null  int64 \n",
      " 1   Score   13999 non-null  object\n",
      " 2   Text    13999 non-null  object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 328.2+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(data[\"Text\"], data[\"Score\"], test_size=0.5, random_state=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TReviews</th>\n",
       "      <th>TTokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9294</th>\n",
       "      <td>Наконец и я созрел до своего отзыва о работе Т...</td>\n",
       "      <td>[созрел, отзыва, работе, ТКС, банка, продуктах...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>Добрый день! Я являюсь клиентом вашего банка, ...</td>\n",
       "      <td>[Добрый, день, являюсь, клиентом, вашего, банк...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3773</th>\n",
       "      <td>Мы организация ООО РуПаб+ 25 июня столкнулись ...</td>\n",
       "      <td>[организация, ООО, РуПаб+, 25, июня, столкнули...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10236</th>\n",
       "      <td>Не так давно имела возможность кредитоваться в...</td>\n",
       "      <td>[возможность, кредитоваться, Лето, Банке, Отзы...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6421</th>\n",
       "      <td>Не могу больше молчать, должен выразить все по...</td>\n",
       "      <td>[молчать, выразить, положительные, моменты, об...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                TReviews  \\\n",
       "9294   Наконец и я созрел до своего отзыва о работе Т...   \n",
       "5299   Добрый день! Я являюсь клиентом вашего банка, ...   \n",
       "3773   Мы организация ООО РуПаб+ 25 июня столкнулись ...   \n",
       "10236  Не так давно имела возможность кредитоваться в...   \n",
       "6421   Не могу больше молчать, должен выразить все по...   \n",
       "\n",
       "                                                 TTokens  \n",
       "9294   [созрел, отзыва, работе, ТКС, банка, продуктах...  \n",
       "5299   [Добрый, день, являюсь, клиентом, вашего, банк...  \n",
       "3773   [организация, ООО, РуПаб+, 25, июня, столкнули...  \n",
       "10236  [возможность, кредитоваться, Лето, Банке, Отзы...  \n",
       "6421   [молчать, выразить, положительные, моменты, об...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "for i in x_train:\n",
    "    doc = nlp(i)\n",
    "    token = [token.text for token in doc if not token.is_stop and not token.is_punct]\n",
    "    tokens.append(token)\n",
    "\n",
    "data2 = pd.DataFrame({\"TReviews\":x_train, \"TTokens\":tokens})\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2[\"X_Train\"] = x_train\n",
    "data2[\"X_Test\"] = x_test\n",
    "data2[\"Y_Train\"] = y_train\n",
    "data2[\"Y_Test\"] = y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idx</th>\n",
       "      <th>Score</th>\n",
       "      <th>Text</th>\n",
       "      <th>TTokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Очень порадовала оперативность работы в банке....</td>\n",
       "      <td>[порадовала, оперативность, работы, банке, Зак...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Имела неосторожность оформить потреб. кредит в...</td>\n",
       "      <td>[неосторожность, оформить, потреб, кредит, Аль...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Небольшая предыстория: Нашел на сайте MDM банк...</td>\n",
       "      <td>[Небольшая, предыстория, Нашел, сайте, MDM, ба...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Не говоря про махинации с бонусами, остановлюс...</td>\n",
       "      <td>[говоря, махинации, бонусами, остановлюсь, про...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>День добрый, моя мама С-на В.А.,1932г рождения...</td>\n",
       "      <td>[День, добрый, мама, В.А.,1932, рождения, пенс...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Всех приветствую.Я являюсь клиентом этого чудо...</td>\n",
       "      <td>[приветствую, являюсь, клиентом, чудо, банка, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Год назад получила кредитку, выбрала банк из-з...</td>\n",
       "      <td>[Год, получила, кредитку, выбрала, банк, стоим...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>В отделении на Автозаводской 01.07.2015 пополн...</td>\n",
       "      <td>[отделении, Автозаводской, 01.07.2015, пополня...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>Искренняя признательность работникам Мособлбан...</td>\n",
       "      <td>[Искренняя, признательность, работникам, Мособ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>Добрый день! Хотелось сказать огромное спасибо...</td>\n",
       "      <td>[Добрый, день, сказать, огромное, спасибо, сот...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>03.02.13 закончился вклад, открытый в Авангард...</td>\n",
       "      <td>[03.02.13, закончился, вклад, открытый, Аванга...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>Сегодня утром, буквально через 40 минут тронус...</td>\n",
       "      <td>[Сегодня, утром, буквально, 40, минут, тронусь...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>Добрый день!С 2010 года являлся клиентом вашег...</td>\n",
       "      <td>[Добрый, день!С, 2010, года, являлся, клиентом...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>Начало моей истории скучно и тривиально. Являю...</td>\n",
       "      <td>[Начало, истории, скучно, тривиально, Являюсь,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>При оформлении кредита в пункте розничных прод...</td>\n",
       "      <td>[оформлении, кредита, пункте, розничных, прода...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    idx  Score                                               Text  \\\n",
       "2     2      1  Очень порадовала оперативность работы в банке....   \n",
       "3     3      0  Имела неосторожность оформить потреб. кредит в...   \n",
       "4     4      0  Небольшая предыстория: Нашел на сайте MDM банк...   \n",
       "7     7      0  Не говоря про махинации с бонусами, остановлюс...   \n",
       "8     8      0  День добрый, моя мама С-на В.А.,1932г рождения...   \n",
       "9     9      0  Всех приветствую.Я являюсь клиентом этого чудо...   \n",
       "10   10      1  Год назад получила кредитку, выбрала банк из-з...   \n",
       "11   11      1  В отделении на Автозаводской 01.07.2015 пополн...   \n",
       "12   12      1  Искренняя признательность работникам Мособлбан...   \n",
       "15   15      1  Добрый день! Хотелось сказать огромное спасибо...   \n",
       "16   16      1  03.02.13 закончился вклад, открытый в Авангард...   \n",
       "19   19      0  Сегодня утром, буквально через 40 минут тронус...   \n",
       "20   20      0  Добрый день!С 2010 года являлся клиентом вашег...   \n",
       "21   21      0  Начало моей истории скучно и тривиально. Являю...   \n",
       "23   23      0  При оформлении кредита в пункте розничных прод...   \n",
       "\n",
       "                                              TTokens  \n",
       "2   [порадовала, оперативность, работы, банке, Зак...  \n",
       "3   [неосторожность, оформить, потреб, кредит, Аль...  \n",
       "4   [Небольшая, предыстория, Нашел, сайте, MDM, ба...  \n",
       "7   [говоря, махинации, бонусами, остановлюсь, про...  \n",
       "8   [День, добрый, мама, В.А.,1932, рождения, пенс...  \n",
       "9   [приветствую, являюсь, клиентом, чудо, банка, ...  \n",
       "10  [Год, получила, кредитку, выбрала, банк, стоим...  \n",
       "11  [отделении, Автозаводской, 01.07.2015, пополня...  \n",
       "12  [Искренняя, признательность, работникам, Мособ...  \n",
       "15  [Добрый, день, сказать, огромное, спасибо, сот...  \n",
       "16  [03.02.13, закончился, вклад, открытый, Аванга...  \n",
       "19  [Сегодня, утром, буквально, 40, минут, тронусь...  \n",
       "20  [Добрый, день!С, 2010, года, являлся, клиентом...  \n",
       "21  [Начало, истории, скучно, тривиально, Являюсь,...  \n",
       "23  [оформлении, кредита, пункте, розничных, прода...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data['Score'] = data['Score'].apply(lambda x: 1 if x == 'Positive' or x == 1 else 0)\n",
    "data[\"TTokens\"] = data2[\"TTokens\"]\n",
    "data = data.mask(data.eq('None')).dropna()\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Have</th>\n",
       "      <th>Must</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>29 июня 2015 г. совершил на свою карту Кукуруз...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546</th>\n",
       "      <td>Добрый день! Являемся клиентами Альфа-Банка ка...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12563</th>\n",
       "      <td>Никогда до этого не был клиентом Альфа-банка, ...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2126</th>\n",
       "      <td>На новоприобретенный номер стали приходить СМС...</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>Зарегистрировал себя вкачестве ИП. Так как у м...</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text      Have  Must\n",
       "2606   29 июня 2015 г. совершил на свою карту Кукуруз...  Negative     0\n",
       "1546   Добрый день! Являемся клиентами Альфа-Банка ка...  Positive     1\n",
       "12563  Никогда до этого не был клиентом Альфа-банка, ...  Negative     0\n",
       "2126   На новоприобретенный номер стали приходить СМС...  Positive     0\n",
       "654    Зарегистрировал себя вкачестве ИП. Так как у м...  Negative     0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "x_train_vectorized = vectorizer.fit_transform(data['TTokens'].apply(lambda x: ' '.join(x)))\n",
    "\n",
    "svm_model = SVC()\n",
    "svm_model.fit(x_train_vectorized, data['Score'])\n",
    "\n",
    "x_test_vectorized = vectorizer.transform(x_test)\n",
    "predictions = svm_model.predict(x_test_vectorized)\n",
    "\n",
    "results = pd.DataFrame({'Text': x_test, 'Have': y_test, 'Must': predictions})\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m new_sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЗдравствуйте! Хочу выразить огромную благодарность специалисту ИОТбанка за выгодный кредит для учебы.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      2\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mДобрый день всем! Я полностью погасила платеж по ипотеке! Но 2 числа вдруг списываются все средства. Никому не советую!\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m sentences_vectorized \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnew_sentences\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(new_sentences_vectorized)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence, prediction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(new_sentences, predictions):\n",
      "File \u001b[1;32mc:\\Users\\Dmitriy Drozhzhin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\series.py:4760\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4627\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4632\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4633\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4634\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4635\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4636\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4751\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4752\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4753\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   4754\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4755\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4756\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4757\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4758\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4759\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m-> 4760\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dmitriy Drozhzhin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1207\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1206\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1207\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dmitriy Drozhzhin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\apply.py:1287\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1281\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1287\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1288\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[0;32m   1289\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1292\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1293\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\Dmitriy Drozhzhin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Dmitriy Drozhzhin\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2920\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[13], line 4\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m new_sentences \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЗдравствуйте! Хочу выразить огромную благодарность специалисту ИОТбанка за выгодный кредит для учебы.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      2\u001b[0m                  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mДобрый день всем! Я полностью погасила платеж по ипотеке! Но 2 числа вдруг списываются все средства. Никому не советую!\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m----> 4\u001b[0m sentences_vectorized \u001b[38;5;241m=\u001b[39m vectorizer\u001b[38;5;241m.\u001b[39mtransform(pd\u001b[38;5;241m.\u001b[39mSeries(new_sentences)\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m)))\n\u001b[0;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m svm_model\u001b[38;5;241m.\u001b[39mpredict(new_sentences_vectorized)\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentence, prediction \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(new_sentences, predictions):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "new_sentences = [\"Здравствуйте! Хочу выразить огромную благодарность специалисту ИОТбанка за выгодный кредит для учебы.\",\n",
    "                 \"Добрый день всем! Я полностью погасила платеж по ипотеке! Но 2 числа вдруг списываются все средства. Никому не советую!\"]\n",
    "\n",
    "sentences_vectorized = vectorizer.transform(pd.Series(new_sentences).apply(lambda x: ' '.join(x.text)))\n",
    "predictions = svm_model.predict(new_sentences_vectorized)\n",
    "\n",
    "for sentence, prediction in zip(new_sentences, predictions):\n",
    "    if prediction == 1:\n",
    "        print(f\"Предложение: {sentence}\\nКлассификация: Positive\\n\")\n",
    "    else:\n",
    "        print(f\"Предложение: {sentence}\\nКлассификация: Negative\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
