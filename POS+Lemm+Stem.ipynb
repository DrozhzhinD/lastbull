{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Dmitriy\n",
      "[nltk_data]     Drozhzhin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Dmitriy\n",
      "[nltk_data]     Drozhzhin\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\Dmitriy\n",
      "[nltk_data]     Drozhzhin\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Импорт библиотеки, загрузка моделей и словаря wordnet\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'started',\n",
       " 'is',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talking',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'doing']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Токенизация текста\n",
    "text = 'The way to get started is to quit talking and begin doing'\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "tokenized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('started', 'VBN'),\n",
       " ('is', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('quit', 'VB'),\n",
       " ('talking', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('begin', 'VB'),\n",
       " ('doing', 'VBG')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# разбор по частям речи\n",
    "tagged = nltk.pos_tag(tokenized)\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VB'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged[3][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'started',\n",
       " 'is',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talking',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'doing']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лемматизация\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemm = WordNetLemmatizer()\n",
    "lemmatized = [lemm.lemmatize(word) for word in tokenized]\n",
    "lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('The', 'DT'),\n",
       " ('way', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('started', 'VBN'),\n",
       " ('is', 'VBZ'),\n",
       " ('to', 'TO'),\n",
       " ('quit', 'VB'),\n",
       " ('talking', 'VBG'),\n",
       " ('and', 'CC'),\n",
       " ('begin', 'VB'),\n",
       " ('doing', 'VBG')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# лемматизация с учетом части речи\n",
    "# меняем теги\n",
    "def pos_tagger(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:          \n",
    "        return None\n",
    "\n",
    "tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'DT'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Dmitriy Drozhzhin\\Downloads\\lastbullsh\\POS+Lemm+Stem.ipynb Ячейка 8\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dmitriy%20Drozhzhin/Downloads/lastbullsh/POS%2BLemm%2BStem.ipynb#X10sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         lemmatized\u001b[39m.\u001b[39mappend(lemm\u001b[39m.\u001b[39mlemmatize(word))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dmitriy%20Drozhzhin/Downloads/lastbullsh/POS%2BLemm%2BStem.ipynb#X10sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Dmitriy%20Drozhzhin/Downloads/lastbullsh/POS%2BLemm%2BStem.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         lemmatized\u001b[39m.\u001b[39mappend(lemm\u001b[39m.\u001b[39;49mlemmatize(word, tag))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Dmitriy%20Drozhzhin/Downloads/lastbullsh/POS%2BLemm%2BStem.ipynb#X10sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m lemmatized\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\stem\\wordnet.py:45\u001b[0m, in \u001b[0;36mWordNetLemmatizer.lemmatize\u001b[1;34m(self, word, pos)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mlemmatize\u001b[39m(\u001b[39mself\u001b[39m, word: \u001b[39mstr\u001b[39m, pos: \u001b[39mstr\u001b[39m \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mn\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mstr\u001b[39m:\n\u001b[0;32m     34\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Lemmatize `word` using WordNet's built-in morphy function.\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[39m    Returns the input word unchanged if it cannot be found in WordNet.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[39m    :return: The lemma of `word`, for the given `pos`.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m     lemmas \u001b[39m=\u001b[39m wn\u001b[39m.\u001b[39;49m_morphy(word, pos)\n\u001b[0;32m     46\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmin\u001b[39m(lemmas, key\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m) \u001b[39mif\u001b[39;00m lemmas \u001b[39melse\u001b[39;00m word\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\nltk\\corpus\\reader\\wordnet.py:2072\u001b[0m, in \u001b[0;36mWordNetCorpusReader._morphy\u001b[1;34m(self, form, pos, check_exceptions)\u001b[0m\n\u001b[0;32m   2064\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_morphy\u001b[39m(\u001b[39mself\u001b[39m, form, pos, check_exceptions\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n\u001b[0;32m   2065\u001b[0m     \u001b[39m# from jordanbg:\u001b[39;00m\n\u001b[0;32m   2066\u001b[0m     \u001b[39m# Given an original string x\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2069\u001b[0m     \u001b[39m# 3. If there are no matches, keep applying rules until you either\u001b[39;00m\n\u001b[0;32m   2070\u001b[0m     \u001b[39m#    find a match or you can't go any further\u001b[39;00m\n\u001b[1;32m-> 2072\u001b[0m     exceptions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_exception_map[pos]\n\u001b[0;32m   2073\u001b[0m     substitutions \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mMORPHOLOGICAL_SUBSTITUTIONS[pos]\n\u001b[0;32m   2075\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mapply_rules\u001b[39m(forms):\n",
      "\u001b[1;31mKeyError\u001b[0m: 'DT'"
     ]
    }
   ],
   "source": [
    "# лемматизируем\n",
    "#tagged = [(word, pos_tagger(tag)) for word, tag in tagged]\n",
    "lemmatized = []\n",
    "for word, tag in tagged:\n",
    "    if tag == None:\n",
    "        lemmatized.append(lemm.lemmatize(word))\n",
    "    else:\n",
    "        lemmatized.append(lemm.lemmatize(word, tag))\n",
    "lemmatized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'way',\n",
       " 'to',\n",
       " 'get',\n",
       " 'start',\n",
       " 'is',\n",
       " 'to',\n",
       " 'quit',\n",
       " 'talk',\n",
       " 'and',\n",
       " 'begin',\n",
       " 'do']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Стемминг English\n",
    "from nltk.stem import SnowballStemmer\n",
    "stemmer = SnowballStemmer(language='english')\n",
    "stemmed = [stemmer.stem(word) for word in tokenized]\n",
    "stemmed\n",
    "'The way to get started is to quit talking and begin doing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['у', 'лукомор', 'дуб', 'зелен', ',', 'злат', 'цеп', 'на', 'дуб', 'том']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Стемминг russian\n",
    "stemmer = SnowballStemmer(language='russian')\n",
    "text = 'У Лукоморья дуб зеленый, златая цепь на дубе том'\n",
    "tokenized = nltk.word_tokenize(text)\n",
    "stemmed = [stemmer.stem(word) for word in tokenized]\n",
    "stemmed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pymorphy\n",
    "https://pymorphy2.readthedocs.io/en/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VERB'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pymorphy2\n",
    "morph = pymorphy2.MorphAnalyzer()\n",
    "morph.parse('стали')[0].tag.POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parse(word='варкалось', tag=OpencorporaTag('NOUN,anim,masc sing,nomn'), normal_form='варкалось', score=0.5000531180282588, methods_stack=((DictionaryAnalyzer(), 'лось', 123, 0), (UnknownPrefixAnalyzer(score_multiplier=0.5), 'варка'))),\n",
       " Parse(word='варкалось', tag=OpencorporaTag('VERB,impf,intr neut,sing,past,indc'), normal_form='варкаться', score=0.4999468819717412, methods_stack=((FakeDictionary(), 'варкалось', 234, 9), (KnownSuffixAnalyzer(min_word_length=4, score_multiplier=0.5), 'алось')))]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'Варкалось'\n",
    "morph.parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
